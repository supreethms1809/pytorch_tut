{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "(178, 13)\n",
      "(178,)\n",
      "tensor([1.3200e+01, 1.7800e+00, 2.1400e+00, 1.1200e+01, 1.0000e+02, 2.6500e+00,\n",
      "        2.7600e+00, 2.6000e-01, 1.2800e+00, 4.3800e+00, 1.0500e+00, 3.4000e+00,\n",
      "        1.0500e+03])\n",
      "tensor(0)\n",
      "Epoch 0 Train Loss: 7.0155863761901855 Test Loss: 11.816423416137695 \n",
      "Epoch 100 Train Loss: 0.5101118683815002 Test Loss: 7.290312767028809 \n",
      "Epoch 200 Train Loss: 0.4214370846748352 Test Loss: 5.170661449432373 \n",
      "Epoch 300 Train Loss: 0.3514251112937927 Test Loss: 5.643611907958984 \n",
      "Epoch 400 Train Loss: 0.3132382333278656 Test Loss: 6.328601360321045 \n",
      "Epoch 500 Train Loss: 0.29512572288513184 Test Loss: 6.807233810424805 \n",
      "Epoch 600 Train Loss: 0.2816993296146393 Test Loss: 7.260745525360107 \n",
      "Epoch 700 Train Loss: 0.2652116119861603 Test Loss: 7.733016014099121 \n",
      "Epoch 800 Train Loss: 0.2595241367816925 Test Loss: 8.058835983276367 \n",
      "Epoch 900 Train Loss: 0.24968111515045166 Test Loss: 8.434120178222656 \n",
      "Epoch 1000 Train Loss: 0.2570251524448395 Test Loss: 8.464335441589355 \n",
      "Epoch 1100 Train Loss: 0.24486656486988068 Test Loss: 8.776235580444336 \n",
      "Epoch 1200 Train Loss: 0.24218210577964783 Test Loss: 9.049266815185547 \n",
      "Epoch 1300 Train Loss: 0.2152683585882187 Test Loss: 9.821320533752441 \n",
      "Epoch 1400 Train Loss: 0.23241129517555237 Test Loss: 8.97933578491211 \n",
      "Epoch 1500 Train Loss: 0.24844327569007874 Test Loss: 9.07418155670166 \n",
      "Epoch 1600 Train Loss: 0.21745432913303375 Test Loss: 9.604631423950195 \n",
      "Epoch 1700 Train Loss: 0.21922199428081512 Test Loss: 9.519719123840332 \n",
      "Epoch 1800 Train Loss: 0.22689750790596008 Test Loss: 9.433959007263184 \n",
      "Epoch 1900 Train Loss: 0.2265612781047821 Test Loss: 9.452528953552246 \n",
      "Epoch 2000 Train Loss: 0.2245100736618042 Test Loss: 9.48005199432373 \n",
      "Epoch 2100 Train Loss: 0.222983255982399 Test Loss: 9.491424560546875 \n",
      "Epoch 2200 Train Loss: 0.2187023013830185 Test Loss: 9.541607856750488 \n",
      "Epoch 2300 Train Loss: 0.21531754732131958 Test Loss: 9.575304985046387 \n",
      "Epoch 2400 Train Loss: 0.2146695852279663 Test Loss: 9.579326629638672 \n",
      "Epoch 2500 Train Loss: 0.21306902170181274 Test Loss: 9.610445022583008 \n",
      "Epoch 2600 Train Loss: 0.2168172001838684 Test Loss: 9.374784469604492 \n",
      "Epoch 2700 Train Loss: 0.21615292131900787 Test Loss: 9.33653736114502 \n",
      "Epoch 2800 Train Loss: 0.2135581523180008 Test Loss: 9.360076904296875 \n",
      "Epoch 2900 Train Loss: 0.212856262922287 Test Loss: 9.29576301574707 \n",
      "Epoch 3000 Train Loss: 0.20961052179336548 Test Loss: 9.228066444396973 \n",
      "Epoch 3100 Train Loss: 0.20626240968704224 Test Loss: 9.321134567260742 \n",
      "Epoch 3200 Train Loss: 0.20206496119499207 Test Loss: 9.394505500793457 \n",
      "Epoch 3300 Train Loss: 0.22229929268360138 Test Loss: 8.964951515197754 \n",
      "Epoch 3400 Train Loss: 0.19700570404529572 Test Loss: 9.35775375366211 \n",
      "Epoch 3500 Train Loss: 0.19233828783035278 Test Loss: 9.610363006591797 \n",
      "Epoch 3600 Train Loss: 0.21057748794555664 Test Loss: 9.094443321228027 \n",
      "Epoch 3700 Train Loss: 0.23453500866889954 Test Loss: 8.633100509643555 \n",
      "Epoch 3800 Train Loss: 0.2185029834508896 Test Loss: 8.688185691833496 \n",
      "Epoch 3900 Train Loss: 0.19271811842918396 Test Loss: 9.217656135559082 \n",
      "Epoch 4000 Train Loss: 0.18834306299686432 Test Loss: 9.368456840515137 \n",
      "Epoch 4100 Train Loss: 0.18647044897079468 Test Loss: 9.462575912475586 \n",
      "Epoch 4200 Train Loss: 0.18497256934642792 Test Loss: 9.547993659973145 \n",
      "Epoch 4300 Train Loss: 0.18389149010181427 Test Loss: 9.556827545166016 \n",
      "Epoch 4400 Train Loss: 0.1906520277261734 Test Loss: 9.105426788330078 \n",
      "Epoch 4500 Train Loss: 0.21868184208869934 Test Loss: 8.60318660736084 \n",
      "Epoch 4600 Train Loss: 0.2364484667778015 Test Loss: 8.237399101257324 \n",
      "Epoch 4700 Train Loss: 0.22972983121871948 Test Loss: 8.149014472961426 \n",
      "Epoch 4800 Train Loss: 0.2100987434387207 Test Loss: 8.262314796447754 \n",
      "Epoch 4900 Train Loss: 0.19470424950122833 Test Loss: 8.513556480407715 \n",
      "Epoch 5000 Train Loss: 0.1837816834449768 Test Loss: 8.793037414550781 \n",
      "Epoch 5100 Train Loss: 0.18115471303462982 Test Loss: 8.864960670471191 \n",
      "Epoch 5200 Train Loss: 0.18017463386058807 Test Loss: 8.865265846252441 \n",
      "Epoch 5300 Train Loss: 0.17869499325752258 Test Loss: 9.066671371459961 \n",
      "Epoch 5400 Train Loss: 0.17799487709999084 Test Loss: 9.052647590637207 \n",
      "Epoch 5500 Train Loss: 0.17728866636753082 Test Loss: 8.867053985595703 \n",
      "Epoch 5600 Train Loss: 0.17749415338039398 Test Loss: 8.757319450378418 \n",
      "Epoch 5700 Train Loss: 0.17720769345760345 Test Loss: 8.940520286560059 \n",
      "Epoch 5800 Train Loss: 0.1796608865261078 Test Loss: 8.96674633026123 \n",
      "Epoch 5900 Train Loss: 0.2129562348127365 Test Loss: 9.362468719482422 \n",
      "Epoch 6000 Train Loss: 0.22965912520885468 Test Loss: 9.50754165649414 \n",
      "Epoch 6100 Train Loss: 0.2538914382457733 Test Loss: 9.678728103637695 \n",
      "Epoch 6200 Train Loss: 0.24251094460487366 Test Loss: 9.589942932128906 \n",
      "Epoch 6300 Train Loss: 0.2793003022670746 Test Loss: 9.826410293579102 \n",
      "Epoch 6400 Train Loss: 0.25823360681533813 Test Loss: 9.685480117797852 \n",
      "Epoch 6500 Train Loss: 0.3029314875602722 Test Loss: 10.190850257873535 \n",
      "Epoch 6600 Train Loss: 0.2649003565311432 Test Loss: 9.982478141784668 \n",
      "Epoch 6700 Train Loss: 0.24607890844345093 Test Loss: 10.017412185668945 \n",
      "Epoch 6800 Train Loss: 0.17989063262939453 Test Loss: 9.423519134521484 \n",
      "Epoch 6900 Train Loss: 0.1793714165687561 Test Loss: 9.355732917785645 \n",
      "Epoch 7000 Train Loss: 0.16871604323387146 Test Loss: 8.773543357849121 \n",
      "Epoch 7100 Train Loss: 0.16751517355442047 Test Loss: 8.768314361572266 \n",
      "Epoch 7200 Train Loss: 0.1672476977109909 Test Loss: 8.84524154663086 \n",
      "Epoch 7300 Train Loss: 0.16677841544151306 Test Loss: 8.80771541595459 \n",
      "Epoch 7400 Train Loss: 0.16657765209674835 Test Loss: 8.727169036865234 \n",
      "Epoch 7500 Train Loss: 0.16684658825397491 Test Loss: 8.738834381103516 \n",
      "Epoch 7600 Train Loss: 0.16753429174423218 Test Loss: 8.63955020904541 \n",
      "Epoch 7700 Train Loss: 0.17720459401607513 Test Loss: 8.815037727355957 \n",
      "Epoch 7800 Train Loss: 0.2345561683177948 Test Loss: 7.2104973793029785 \n",
      "Epoch 7900 Train Loss: 0.2579343020915985 Test Loss: 7.046921253204346 \n",
      "Epoch 8000 Train Loss: 0.22988371551036835 Test Loss: 7.29934024810791 \n",
      "Epoch 8100 Train Loss: 0.21614103019237518 Test Loss: 7.403596878051758 \n",
      "Epoch 8200 Train Loss: 0.20508630573749542 Test Loss: 7.522542476654053 \n",
      "Epoch 8300 Train Loss: 0.20286275446414948 Test Loss: 7.53346061706543 \n",
      "Epoch 8400 Train Loss: 0.20597165822982788 Test Loss: 7.495959758758545 \n",
      "Epoch 8500 Train Loss: 0.19373780488967896 Test Loss: 7.622190475463867 \n",
      "Epoch 8600 Train Loss: 0.20249322056770325 Test Loss: 7.51846981048584 \n",
      "Epoch 8700 Train Loss: 0.19088514149188995 Test Loss: 7.663510322570801 \n",
      "Epoch 8800 Train Loss: 0.19375531375408173 Test Loss: 7.609079837799072 \n",
      "Epoch 8900 Train Loss: 0.1861726939678192 Test Loss: 7.7394490242004395 \n",
      "Epoch 9000 Train Loss: 0.18473488092422485 Test Loss: 7.733646869659424 \n",
      "Epoch 9100 Train Loss: 0.17600694298744202 Test Loss: 7.9126057624816895 \n",
      "Epoch 9200 Train Loss: 0.1730370968580246 Test Loss: 7.986959934234619 \n",
      "Epoch 9300 Train Loss: 0.17287501692771912 Test Loss: 7.978000164031982 \n",
      "Epoch 9400 Train Loss: 0.16707617044448853 Test Loss: 8.142925262451172 \n",
      "Epoch 9500 Train Loss: 0.16739903390407562 Test Loss: 8.129551887512207 \n",
      "Epoch 9600 Train Loss: 0.16080564260482788 Test Loss: 8.32596492767334 \n",
      "Epoch 9700 Train Loss: 0.15996187925338745 Test Loss: 8.389493942260742 \n",
      "Epoch 9800 Train Loss: 0.1614813655614853 Test Loss: 8.334297180175781 \n",
      "Epoch 9900 Train Loss: 0.1595999002456665 Test Loss: 8.445932388305664 \n",
      "Epoch 10000 Train Loss: 0.15696997940540314 Test Loss: 8.62394905090332 \n",
      "Epoch 10100 Train Loss: 0.1675429344177246 Test Loss: 8.109792709350586 \n",
      "Epoch 10200 Train Loss: 0.17454908788204193 Test Loss: 8.077788352966309 \n",
      "Epoch 10300 Train Loss: 0.15742127597332 Test Loss: 8.52764892578125 \n",
      "Epoch 10400 Train Loss: 0.1684546172618866 Test Loss: 8.015172004699707 \n",
      "Epoch 10500 Train Loss: 0.16327333450317383 Test Loss: 8.18191909790039 \n",
      "Epoch 10600 Train Loss: 0.15584054589271545 Test Loss: 8.52599811553955 \n",
      "Epoch 10700 Train Loss: 0.16040891408920288 Test Loss: 8.933579444885254 \n",
      "Epoch 10800 Train Loss: 0.15767112374305725 Test Loss: 8.865031242370605 \n",
      "Epoch 10900 Train Loss: 0.1544492542743683 Test Loss: 8.643335342407227 \n",
      "Epoch 11000 Train Loss: 0.15708006918430328 Test Loss: 8.919429779052734 \n",
      "Epoch 11100 Train Loss: 0.1536957174539566 Test Loss: 8.755173683166504 \n",
      "Epoch 11200 Train Loss: 0.1529998928308487 Test Loss: 8.727546691894531 \n",
      "Epoch 11300 Train Loss: 0.15483537316322327 Test Loss: 8.553372383117676 \n",
      "Epoch 11400 Train Loss: 0.15223319828510284 Test Loss: 8.827848434448242 \n",
      "Epoch 11500 Train Loss: 0.15531471371650696 Test Loss: 9.059998512268066 \n",
      "Epoch 11600 Train Loss: 0.1548004001379013 Test Loss: 9.05806827545166 \n",
      "Epoch 11700 Train Loss: 0.15108622610569 Test Loss: 8.899161338806152 \n",
      "Epoch 11800 Train Loss: 0.1586468517780304 Test Loss: 9.21794319152832 \n",
      "Epoch 11900 Train Loss: 0.15897566080093384 Test Loss: 9.299135208129883 \n",
      "Epoch 12000 Train Loss: 0.17457351088523865 Test Loss: 9.584359169006348 \n",
      "Epoch 12100 Train Loss: 0.1934763640165329 Test Loss: 9.797554016113281 \n",
      "Epoch 12200 Train Loss: 0.21471044421195984 Test Loss: 9.928486824035645 \n",
      "Epoch 12300 Train Loss: 0.23368754982948303 Test Loss: 9.996891975402832 \n",
      "Epoch 12400 Train Loss: 0.24120169878005981 Test Loss: 9.965950965881348 \n",
      "Epoch 12500 Train Loss: 0.22666476666927338 Test Loss: 9.793004035949707 \n",
      "Epoch 12600 Train Loss: 0.20534898340702057 Test Loss: 9.604228973388672 \n",
      "Epoch 12700 Train Loss: 0.18911367654800415 Test Loss: 9.430266380310059 \n",
      "Epoch 12800 Train Loss: 0.17693732678890228 Test Loss: 9.313145637512207 \n",
      "Epoch 12900 Train Loss: 0.16573727130889893 Test Loss: 9.187786102294922 \n",
      "Epoch 13000 Train Loss: 0.15696275234222412 Test Loss: 9.049108505249023 \n",
      "Epoch 13100 Train Loss: 0.15228547155857086 Test Loss: 8.951923370361328 \n",
      "Epoch 13200 Train Loss: 0.14947742223739624 Test Loss: 8.84313678741455 \n",
      "Epoch 13300 Train Loss: 0.14887291193008423 Test Loss: 8.852927207946777 \n",
      "Epoch 13400 Train Loss: 0.14825688302516937 Test Loss: 8.861536979675293 \n",
      "Epoch 13500 Train Loss: 0.14783398807048798 Test Loss: 8.883660316467285 \n",
      "Epoch 13600 Train Loss: 0.14731435477733612 Test Loss: 8.908447265625 \n",
      "Epoch 13700 Train Loss: 0.14695316553115845 Test Loss: 8.93353271484375 \n",
      "Epoch 13800 Train Loss: 0.1468062847852707 Test Loss: 8.860628128051758 \n",
      "Epoch 13900 Train Loss: 0.14899469912052155 Test Loss: 8.66191291809082 \n",
      "Epoch 14000 Train Loss: 0.1529717892408371 Test Loss: 8.540375709533691 \n",
      "Epoch 14100 Train Loss: 0.1781972497701645 Test Loss: 8.136894226074219 \n",
      "Epoch 14200 Train Loss: 0.2161984145641327 Test Loss: 10.07813549041748 \n",
      "Epoch 14300 Train Loss: 0.23162239789962769 Test Loss: 10.121809959411621 \n",
      "Epoch 14400 Train Loss: 0.22861987352371216 Test Loss: 9.981728553771973 \n",
      "Epoch 14500 Train Loss: 0.20172132551670074 Test Loss: 7.669246196746826 \n",
      "Epoch 14600 Train Loss: 0.19006645679473877 Test Loss: 7.804863929748535 \n",
      "Epoch 14700 Train Loss: 0.1780840903520584 Test Loss: 7.90989351272583 \n",
      "Epoch 14800 Train Loss: 0.1704900562763214 Test Loss: 8.023824691772461 \n",
      "Epoch 14900 Train Loss: 0.16239790618419647 Test Loss: 8.177506446838379 \n",
      "Epoch 15000 Train Loss: 0.15642239153385162 Test Loss: 8.359601020812988 \n",
      "Epoch 15100 Train Loss: 0.1530870497226715 Test Loss: 9.173295021057129 \n",
      "Epoch 15200 Train Loss: 0.1470710188150406 Test Loss: 9.001766204833984 \n",
      "Epoch 15300 Train Loss: 0.14605318009853363 Test Loss: 8.978875160217285 \n",
      "Epoch 15400 Train Loss: 0.14511720836162567 Test Loss: 8.94426155090332 \n",
      "Epoch 15500 Train Loss: 0.1447567641735077 Test Loss: 8.917170524597168 \n",
      "Epoch 15600 Train Loss: 0.14435450732707977 Test Loss: 8.976963996887207 \n",
      "Epoch 15700 Train Loss: 0.14396733045578003 Test Loss: 9.009561538696289 \n",
      "Epoch 15800 Train Loss: 0.1436828374862671 Test Loss: 9.024246215820312 \n",
      "Epoch 15900 Train Loss: 0.1433625966310501 Test Loss: 9.03928279876709 \n",
      "Epoch 16000 Train Loss: 0.14312154054641724 Test Loss: 9.065018653869629 \n",
      "Epoch 16100 Train Loss: 0.14284686744213104 Test Loss: 9.086026191711426 \n",
      "Epoch 16200 Train Loss: 0.14264452457427979 Test Loss: 9.0991849899292 \n",
      "Epoch 16300 Train Loss: 0.14234080910682678 Test Loss: 9.123063087463379 \n",
      "Epoch 16400 Train Loss: 0.142104834318161 Test Loss: 9.144859313964844 \n",
      "Epoch 16500 Train Loss: 0.1419159322977066 Test Loss: 9.150327682495117 \n",
      "Epoch 16600 Train Loss: 0.14186033606529236 Test Loss: 9.226863861083984 \n",
      "Epoch 16700 Train Loss: 0.1419202983379364 Test Loss: 9.003901481628418 \n",
      "Epoch 16800 Train Loss: 0.14304544031620026 Test Loss: 9.373696327209473 \n",
      "Epoch 16900 Train Loss: 0.14292526245117188 Test Loss: 9.386849403381348 \n",
      "Epoch 17000 Train Loss: 0.14558589458465576 Test Loss: 9.496481895446777 \n",
      "Epoch 17100 Train Loss: 0.145594522356987 Test Loss: 9.522768020629883 \n",
      "Epoch 17200 Train Loss: 0.1454850137233734 Test Loss: 9.524456024169922 \n",
      "Epoch 17300 Train Loss: 0.14525547623634338 Test Loss: 9.53174877166748 \n",
      "Epoch 17400 Train Loss: 0.1465734839439392 Test Loss: 9.585321426391602 \n",
      "Epoch 17500 Train Loss: 0.14303812384605408 Test Loss: 8.913207054138184 \n",
      "Epoch 17600 Train Loss: 0.14199599623680115 Test Loss: 9.43365478515625 \n",
      "Epoch 17700 Train Loss: 0.14036455750465393 Test Loss: 9.31613540649414 \n",
      "Epoch 17800 Train Loss: 0.14026905596256256 Test Loss: 9.315038681030273 \n",
      "Epoch 17900 Train Loss: 0.140153706073761 Test Loss: 9.318527221679688 \n",
      "Epoch 18000 Train Loss: 0.13982675969600677 Test Loss: 9.264385223388672 \n",
      "Epoch 18100 Train Loss: 0.1397780478000641 Test Loss: 9.264533996582031 \n",
      "Epoch 18200 Train Loss: 0.13971629738807678 Test Loss: 9.255609512329102 \n",
      "Epoch 18300 Train Loss: 0.1396985948085785 Test Loss: 9.2489595413208 \n",
      "Epoch 18400 Train Loss: 0.13961686193943024 Test Loss: 9.254560470581055 \n",
      "Epoch 18500 Train Loss: 0.1395721137523651 Test Loss: 9.256863594055176 \n",
      "Epoch 18600 Train Loss: 0.1395554095506668 Test Loss: 9.245293617248535 \n",
      "Epoch 18700 Train Loss: 0.1395227164030075 Test Loss: 9.242158889770508 \n",
      "Epoch 18800 Train Loss: 0.13957910239696503 Test Loss: 9.232661247253418 \n",
      "Epoch 18900 Train Loss: 0.13955111801624298 Test Loss: 9.224430084228516 \n",
      "Epoch 19000 Train Loss: 0.13954272866249084 Test Loss: 9.211722373962402 \n",
      "Epoch 19100 Train Loss: 0.13958479464054108 Test Loss: 9.208715438842773 \n",
      "Epoch 19200 Train Loss: 0.13959236443042755 Test Loss: 9.189908981323242 \n",
      "Epoch 19300 Train Loss: 0.13957920670509338 Test Loss: 9.17885684967041 \n",
      "Epoch 19400 Train Loss: 0.13962990045547485 Test Loss: 9.16847038269043 \n",
      "Epoch 19500 Train Loss: 0.13981327414512634 Test Loss: 9.206597328186035 \n",
      "Epoch 19600 Train Loss: 0.14009332656860352 Test Loss: 9.085251808166504 \n",
      "Epoch 19700 Train Loss: 0.14120450615882874 Test Loss: 8.995515823364258 \n",
      "Epoch 19800 Train Loss: 0.1478751301765442 Test Loss: 9.471567153930664 \n",
      "Epoch 19900 Train Loss: 0.15731069445610046 Test Loss: 8.460054397583008 \n",
      "Epoch 20000 Train Loss: 0.17710378766059875 Test Loss: 9.870025634765625 \n",
      "Epoch 20100 Train Loss: 0.1936512142419815 Test Loss: 10.04731559753418 \n",
      "Epoch 20200 Train Loss: 0.22762088477611542 Test Loss: 10.371687889099121 \n",
      "Epoch 20300 Train Loss: 0.2091302126646042 Test Loss: 8.02663803100586 \n",
      "Epoch 20400 Train Loss: 0.19181977212429047 Test Loss: 10.390364646911621 \n",
      "Epoch 20500 Train Loss: 0.1527668982744217 Test Loss: 8.800005912780762 \n",
      "Epoch 20600 Train Loss: 0.13689211010932922 Test Loss: 9.447395324707031 \n",
      "Epoch 20700 Train Loss: 0.13709938526153564 Test Loss: 9.413972854614258 \n",
      "Epoch 20800 Train Loss: 0.1373179405927658 Test Loss: 9.372581481933594 \n",
      "Epoch 20900 Train Loss: 0.1375754028558731 Test Loss: 9.346357345581055 \n",
      "Epoch 21000 Train Loss: 0.1378234177827835 Test Loss: 9.287813186645508 \n",
      "Epoch 21100 Train Loss: 0.13807076215744019 Test Loss: 9.294106483459473 \n",
      "Epoch 21200 Train Loss: 0.13870179653167725 Test Loss: 9.315896987915039 \n",
      "Epoch 21300 Train Loss: 0.14426955580711365 Test Loss: 8.906389236450195 \n",
      "Epoch 21400 Train Loss: 0.1738915890455246 Test Loss: 9.928047180175781 \n",
      "Epoch 21500 Train Loss: 0.18540328741073608 Test Loss: 8.193113327026367 \n",
      "Epoch 21600 Train Loss: 0.23464426398277283 Test Loss: 10.589629173278809 \n",
      "Epoch 21700 Train Loss: 0.17740404605865479 Test Loss: 8.514893531799316 \n",
      "Epoch 21800 Train Loss: 0.1381068229675293 Test Loss: 9.735533714294434 \n",
      "Epoch 21900 Train Loss: 0.13591785728931427 Test Loss: 9.480147361755371 \n",
      "Epoch 22000 Train Loss: 0.1362425982952118 Test Loss: 9.44137954711914 \n",
      "Epoch 22100 Train Loss: 0.1365339308977127 Test Loss: 9.389994621276855 \n",
      "Epoch 22200 Train Loss: 0.13692475855350494 Test Loss: 9.351202011108398 \n",
      "Epoch 22300 Train Loss: 0.13734064996242523 Test Loss: 9.36202621459961 \n",
      "Epoch 22400 Train Loss: 0.14169959723949432 Test Loss: 9.526476860046387 \n",
      "Epoch 22500 Train Loss: 0.16415287554264069 Test Loss: 8.43943977355957 \n",
      "Epoch 22600 Train Loss: 0.2015857994556427 Test Loss: 10.303699493408203 \n",
      "Epoch 22700 Train Loss: 0.20936214923858643 Test Loss: 8.128318786621094 \n",
      "Epoch 22800 Train Loss: 0.1619185507297516 Test Loss: 10.295313835144043 \n",
      "Epoch 22900 Train Loss: 0.1352899670600891 Test Loss: 9.62789535522461 \n",
      "Epoch 23000 Train Loss: 0.13526304066181183 Test Loss: 9.523643493652344 \n",
      "Epoch 23100 Train Loss: 0.1355242282152176 Test Loss: 9.471780776977539 \n",
      "Epoch 23200 Train Loss: 0.13577918708324432 Test Loss: 9.437764167785645 \n",
      "Epoch 23300 Train Loss: 0.13610845804214478 Test Loss: 9.431462287902832 \n",
      "Epoch 23400 Train Loss: 0.1366100013256073 Test Loss: 9.283341407775879 \n",
      "Epoch 23500 Train Loss: 0.15546952188014984 Test Loss: 9.884688377380371 \n",
      "Epoch 23600 Train Loss: 0.1718463897705078 Test Loss: 8.406729698181152 \n",
      "Epoch 23700 Train Loss: 0.18999789655208588 Test Loss: 8.296149253845215 \n",
      "Epoch 23800 Train Loss: 0.2044302523136139 Test Loss: 10.66514778137207 \n",
      "Epoch 23900 Train Loss: 0.1402510553598404 Test Loss: 9.958958625793457 \n",
      "Epoch 24000 Train Loss: 0.13436739146709442 Test Loss: 9.57087230682373 \n",
      "Epoch 24100 Train Loss: 0.1346844881772995 Test Loss: 9.532859802246094 \n",
      "Epoch 24200 Train Loss: 0.1349988728761673 Test Loss: 9.482023239135742 \n",
      "Epoch 24300 Train Loss: 0.13530555367469788 Test Loss: 9.47553825378418 \n",
      "Epoch 24400 Train Loss: 0.13589459657669067 Test Loss: 9.32044792175293 \n",
      "Epoch 24500 Train Loss: 0.1517709642648697 Test Loss: 8.72376537322998 \n",
      "Epoch 24600 Train Loss: 0.20203912258148193 Test Loss: 10.44218635559082 \n",
      "Epoch 24700 Train Loss: 0.20229366421699524 Test Loss: 10.698311805725098 \n",
      "Epoch 24800 Train Loss: 0.1370585560798645 Test Loss: 9.308403015136719 \n",
      "Epoch 24900 Train Loss: 0.13382947444915771 Test Loss: 9.598381042480469 \n",
      "Epoch 25000 Train Loss: 0.1341591626405716 Test Loss: 9.554144859313965 \n",
      "Epoch 25100 Train Loss: 0.1345016211271286 Test Loss: 9.511573791503906 \n",
      "Epoch 25200 Train Loss: 0.13503225147724152 Test Loss: 9.403386116027832 \n",
      "Epoch 25300 Train Loss: 0.15480776131153107 Test Loss: 9.963618278503418 \n",
      "Epoch 25400 Train Loss: 0.1860319823026657 Test Loss: 8.335189819335938 \n",
      "Epoch 25500 Train Loss: 0.20290634036064148 Test Loss: 10.724235534667969 \n",
      "Epoch 25600 Train Loss: 0.13378699123859406 Test Loss: 9.446221351623535 \n",
      "Epoch 25700 Train Loss: 0.13338187336921692 Test Loss: 9.614336967468262 \n",
      "Epoch 25800 Train Loss: 0.13373427093029022 Test Loss: 9.564348220825195 \n",
      "Epoch 25900 Train Loss: 0.13411815464496613 Test Loss: 9.491881370544434 \n",
      "Epoch 26000 Train Loss: 0.1358538419008255 Test Loss: 9.306753158569336 \n",
      "Epoch 26100 Train Loss: 0.15718905627727509 Test Loss: 8.698362350463867 \n",
      "Epoch 26200 Train Loss: 0.21642130613327026 Test Loss: 10.732756614685059 \n",
      "Epoch 26300 Train Loss: 0.14475436508655548 Test Loss: 9.114947319030762 \n",
      "Epoch 26400 Train Loss: 0.13275489211082458 Test Loss: 9.661812782287598 \n",
      "Epoch 26500 Train Loss: 0.133114293217659 Test Loss: 9.603680610656738 \n",
      "Epoch 26600 Train Loss: 0.13347233831882477 Test Loss: 9.561067581176758 \n",
      "Epoch 26700 Train Loss: 0.1340041309595108 Test Loss: 9.459481239318848 \n",
      "Epoch 26800 Train Loss: 0.1553732454776764 Test Loss: 10.035719871520996 \n",
      "Epoch 26900 Train Loss: 0.19660300016403198 Test Loss: 8.34026050567627 \n",
      "Epoch 27000 Train Loss: 0.15352389216423035 Test Loss: 10.365745544433594 \n",
      "Epoch 27100 Train Loss: 0.13234804570674896 Test Loss: 9.690316200256348 \n",
      "Epoch 27200 Train Loss: 0.13272252678871155 Test Loss: 9.626801490783691 \n",
      "Epoch 27300 Train Loss: 0.1331193596124649 Test Loss: 9.568202018737793 \n",
      "Epoch 27400 Train Loss: 0.1338714361190796 Test Loss: 9.586535453796387 \n",
      "Epoch 27500 Train Loss: 0.15838508307933807 Test Loss: 10.106488227844238 \n",
      "Epoch 27600 Train Loss: 0.2159997522830963 Test Loss: 10.74540901184082 \n",
      "Epoch 27700 Train Loss: 0.14494125545024872 Test Loss: 10.261344909667969 \n",
      "Epoch 27800 Train Loss: 0.13194100558757782 Test Loss: 9.707145690917969 \n",
      "Epoch 27900 Train Loss: 0.13230162858963013 Test Loss: 9.64747142791748 \n",
      "Epoch 28000 Train Loss: 0.13270612061023712 Test Loss: 9.586194038391113 \n",
      "Epoch 28100 Train Loss: 0.133815735578537 Test Loss: 9.427796363830566 \n",
      "Epoch 28200 Train Loss: 0.16364532709121704 Test Loss: 8.689094543457031 \n",
      "Epoch 28300 Train Loss: 0.20919185876846313 Test Loss: 10.868508338928223 \n",
      "Epoch 28400 Train Loss: 0.1317669302225113 Test Loss: 9.850104331970215 \n",
      "Epoch 28500 Train Loss: 0.1317741721868515 Test Loss: 9.698333740234375 \n",
      "Epoch 28600 Train Loss: 0.13219410181045532 Test Loss: 9.627256393432617 \n",
      "Epoch 28700 Train Loss: 0.13275346159934998 Test Loss: 9.518741607666016 \n",
      "Epoch 28800 Train Loss: 0.1558682769536972 Test Loss: 8.778177261352539 \n",
      "Epoch 28900 Train Loss: 0.2106318324804306 Test Loss: 10.899311065673828 \n",
      "Epoch 29000 Train Loss: 0.13105638325214386 Test Loss: 9.780427932739258 \n",
      "Epoch 29100 Train Loss: 0.1314939707517624 Test Loss: 9.700242042541504 \n",
      "Epoch 29200 Train Loss: 0.13193613290786743 Test Loss: 9.641724586486816 \n",
      "Epoch 29300 Train Loss: 0.13270460069179535 Test Loss: 9.49329662322998 \n",
      "Epoch 29400 Train Loss: 0.17055924236774445 Test Loss: 8.64240837097168 \n",
      "Epoch 29500 Train Loss: 0.16807182133197784 Test Loss: 10.676365852355957 \n",
      "Epoch 29600 Train Loss: 0.13088847696781158 Test Loss: 9.766242980957031 \n",
      "Epoch 29700 Train Loss: 0.13131681084632874 Test Loss: 9.693245887756348 \n",
      "Epoch 29800 Train Loss: 0.13181717693805695 Test Loss: 9.606968879699707 \n",
      "Epoch 29900 Train Loss: 0.1486266702413559 Test Loss: 10.061934471130371 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x239668fcf70>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(wine.keys())\n",
    "X = wine[\"data\"]\n",
    "Y = wine[\"target\"]\n",
    "feature_names = wine[\"feature_names\"]\n",
    "\n",
    "print(X.shape), print(Y.shape)\n",
    "\n",
    "train_len = int(len(X) * 0.7)\n",
    "X_train = X[:train_len]\n",
    "X_test = X[train_len:]\n",
    "Y_train = Y[:train_len]\n",
    "Y_test = Y[train_len:]\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "Y_test = Y_test.to(device)\n",
    "\n",
    "print(X_train[1]), print(Y_train[1])\n",
    "\n",
    "hidden_layer = 10\n",
    "class WineClassifier(nn.Module):\n",
    "    def __init__(self,hidden_layer):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(13, hidden_layer)\n",
    "        self.layer2 = nn.Linear(hidden_layer, hidden_layer)\n",
    "        self.layer3 = nn.Linear(hidden_layer, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "        # x = self.layer1(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.layer2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.layer3(x)\n",
    "        # x = self.softmax(x)\n",
    "        # return x\n",
    "    \n",
    "    \n",
    "model = WineClassifier(hidden_layer).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)\n",
    "epochs = 30000\n",
    "\n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    Y_pred = model(X_train)\n",
    "    y_pred = torch.softmax(Y_pred, dim=1).argmax(dim=1)\n",
    "    #print(f\"Value of y_prediction: {y_pred.dtype}\")\n",
    "    #print(f\"Value of Y_Train: {Y_train.dtype}\")\n",
    "    loss = loss_fn(Y_pred, Y_train)\n",
    "    epoch_list.append(epoch)\n",
    "    loss_list.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred_test = model(X_test)\n",
    "        test_pred = torch.softmax(Y_pred_test, dim=1).argmax(dim=1)\n",
    "        test_loss = loss_fn(Y_pred_test, Y_test)\n",
    "        test_loss_list.append(test_loss.item())\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} Train Loss: {loss.item()} Test Loss: {test_loss.item()} \")\n",
    "\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_list, loss_list, label=\"Train Loss\")\n",
    "plt.plot(epoch_list, test_loss_list, label=\"Test Loss\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)\n",
    "\n",
    "from helper_functions import plot_predictions, plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10201x2 and 13x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mplot_decision_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Documents\\GitHub\\pytorch_tut\\01\\helper_functions.py:58\u001b[0m, in \u001b[0;36mplot_decision_boundary\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m---> 58\u001b[0m     y_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_to_pred_on\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Test for multi-class or binary and adjust logits to prediction labels\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(torch\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Anaconda3\\envs\\transfomers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Anaconda3\\envs\\transfomers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 40\u001b[0m, in \u001b[0;36mWineClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))))\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Anaconda3\\envs\\transfomers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Anaconda3\\envs\\transfomers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ssuresh\\Anaconda3\\envs\\transfomers\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10201x2 and 13x10)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plot decision boundaries for training and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_decision_boundary(model, X_train, Y_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_decision_boundary(model, X_test, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transfomers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
